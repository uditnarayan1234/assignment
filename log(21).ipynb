{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "343308ab-793c-4f17-af3e-b648b8eeb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "\n",
    "## The purpose of Grid Search CV in machine learning is to perform hyperparameter tuning to determine the optimal values for a given model. Here’s how it works:\n",
    "## Cross-Validation: Grid Search CV then systematically creates and evaluates model versions for each combination of parameters in your grid\n",
    "## Selection of the Best Model: Once all models have been evaluated, Grid Search CV selects the combination of parameters that resulted in the best performance for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433ed72a-6e06-4969-a393-5c83d960a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "## Data leakage in machine learning refers to a situation where information from outside the training dataset is used to create the model.\n",
    "##  This can happen when the training data contains information that will not be available when the model is used for prediction\n",
    "## Example of Data Leakage: Imagine you’re building a model to predict whether a loan will default. If the dataset includes \n",
    "##  a feature that indicates post-loan actions (like recovery efforts), the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1817d855-e57c-48d6-aa29-3090615a076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4. How can you prevent data leakage when building a machine learning model?\n",
    "\n",
    "## Preventing data leakage is essential to ensure the robustness and generalizability of a machine learning model. Here are some strategies to prevent data leakage:\n",
    "## Careful Data Management: Ensure a strict separation between training and test datasets.\n",
    "## conduct no feature with tranning the data for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96effe4-2df4-4f74-9704-cd0826325710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\n",
    "### A confusion matrix is a table used to evaluate the performance of a classification model. It provides a summary of how well the model’s predictions\n",
    "## True Positives (TP): The number of positive instances correctly predicted as positive.\n",
    "## True Negatives (TN): The number of negative instances correctly predicted as negative.\n",
    "## False Positives (FP): The number of negative instances incorrectly predicted as positive (Type I error).\n",
    "##n False Negatives (FN): The number of positive instances incorrectly predicted as negative (Type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "becf83fe-9518-4da8-be67-2944c3400d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "## In the context of a confusion matrix, precision and recall are two important metrics \n",
    "## Precision (also known as Positive Predictive Value) measures the accuracy of the positive predictions made by the model. It is the ratio of correctly\n",
    "## The formula for precision is:\n",
    "## Precision=TP+FPTP\n",
    "\n",
    "## Recall (also known as Sensitivity or True Positive Rate) measures the model’s ability to identify all relevant instances within a datase\n",
    "## Precision focuses on the purity of the positive predictions, meaning it is more concerned with whether the positive predictions made are correct.\n",
    "## Recall focuses on the completeness of the positive predictions, meaning it is more concerned with capturing all possible positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eea9c8e-e795-4902-ba15-4207de8d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "## Interpreting a confusion matrix involves analyzing the four different outcomes—True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives \n",
    "## True Positives (TP): These are cases where the model correctly predicts the positive class. High TP indicates the model is good at identifying the positive class.\n",
    "## True Negatives (TN): These are cases where the model correctly predicts the negative class. High TN indicates the model is good at identifying the negative class.\n",
    "## False Positives (FP), also known as Type I errors: These occur when the model incorrectly predicts the positive class. High FP means the model is seeing things.\n",
    "## False Negatives (FN), also known as Type II errors: These occur when the model fails to predict the positive class. High FN means the model is missing things that are th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af41d22-2f4a-4f47-93bb-8e62baf5cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "## The accuracy of a model is directly related to the values in its confusion matrix. It is calculated as the sum of the true positives (TP) and true negatives (TN)\n",
    "##his formula shows that accuracy is the proportion of correct predictions (both positive and negative) made by the model out of all predictions.\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d50998-6e97-46b7-b8d1-46f9ab68dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "##model?\n",
    "## A confusion matrix can be a valuable tool for identifying potential biases or limitations in your machine learning model by revealing patterns in the errors it makes\n",
    "## class imbalance: confusion matrix shows the high number of positive negative\n",
    "## error analysis: expaltion behind the false positive help to uncover the data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba86509-1cf4-4ef5-bbb2-41b3f6b59341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
