{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f6e0ec-2ced-40b3-a470-7699cbb28cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. What is an ensemble technique in machine learning?\n",
    "\n",
    "##  Ensemble learning is a powerful technique in machine learning that combines the predictions from multiple individual \n",
    "##   models to improve overall predictive performance. Here are the key points about ensemble learning\n",
    "## Improved Accuracy: Combining multiple models often leads to better accuracy than any single model.\n",
    "## Robustness: Ensembles are more resilient to outliers and individual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01778a2-d8b1-4c41-9e3f-15f2b3b8eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2. Why are ensemble techniques used in machine learning?\n",
    "\n",
    "##  Improved Accuracy: Combining multiple models often leads to better accuracy than any single model.\n",
    "## Robustness: Ensembles are more resilient to outliers and individual data points.\n",
    "## Compensation: Ensemble methods compensate for poor learning algorithms by combining their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a2d113-9fad-4be8-8ea5-a037353118f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3. What is bagging?\n",
    "\n",
    "## Randomly sample subsets (with replacement) from the training data.\n",
    "## Train individual models (often the same type, e.g., decision trees) on these bootstrapped samples.\n",
    "## Reduced Variance: Bagging reduces variance by averaging predictions from diverse models.\n",
    "## Robustness: It makes the model more robust to outliers and noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d014ae-c203-41f3-bb5b-9a5464b78c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q4. What is boosting?\n",
    "\n",
    "##Boosting is an ensemble technique in machine learning that aims to build a strong classifier by combining multiple weak classifiers\n",
    "##nitialization: Start with a dataset and assign equal weights to each data point.\n",
    "## Model Training: Train a weak model (e.g., decision tree) on the weighted dataset.\n",
    "## Error Correction: Identify the data points that the model misclassifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbdd20c-95ad-4e83-aebb-797d8ee61947",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q5. What are the benefits of using ensemble techniques?\n",
    "\n",
    "## Handling Imbalanced Data:\n",
    "## Ensembles can handle imbalanced datasets effectively.\n",
    "## By combining models, they focus more on misclassified points, improving performance on minority classes.\n",
    "## Some ensemble techniques break down the decision process into steps (e.g., boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5b59bd-a659-470b-803a-7eba16600b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q6. Are ensemble techniques always better than individual models?\n",
    "\n",
    "## Trade-offs:\n",
    "## Complexity: Ensembles introduce additional complexity due to model combination and aggregation.\n",
    "## Interpretability: Individual models are often easier to interpret than complex ensemble decisions.\n",
    "\n",
    "## Guidelines:\n",
    "## Experiment: Evaluate both individual models and ensembles on your specific dataset.\n",
    "## Domain Knowledge: Consider the nature of the problem and the strengths of different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0f49f1-a25b-4ae0-8320-68fcd57713b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q7. How is the confidence interval calculated using bootstrap?\n",
    "\n",
    "## Steps for Calculating a Bootstrap Confidence Interval:\n",
    "## Hereâ€™s how you can use bootstrap to estimate a confidence interval:\n",
    "## Original Data: Start with your original dataset (with (n) observations).\n",
    "## Resampling: Randomly sample (n) observations with replacement from the original data. This generates a new dataset (a bootstrap sample) of the same size as the original.\n",
    "## Statistic Calculation: Calculate the statistic of interest (e.g., mean, median, standard deviation) for each bootstrap sample.\n",
    "## Repeat: Repeat steps 2 and 3 a large number of times (typically (B) times) to create a distribution of bootstrap estimates for the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b922e9-ff47-4521-aa19-b82c8eb7c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\n",
    "## Responsive Design:\n",
    "# Bootstrap ensures that your web pages adapt seamlessly to different screen sizes (from desktops to mobile devices).\n",
    "# It follows a mobile-first approach, prioritizing mobile design and progressively enhancing it for larger screens.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
