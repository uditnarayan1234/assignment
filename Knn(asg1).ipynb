{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857c8114-3b14-4fc3-b40d-4bf0ae21ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. What is the KNN algorithm?\n",
    "\n",
    "## The K-Nearest Neighbors (KNN) algorithm is a supervised machine learning method used for both classification and regression tasks.\n",
    "## KNN is a non-parametric algorithm, meaning it doesnâ€™t make any underlying assumptions about the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7968d496-8ebe-4cd2-ad8b-941fd75b3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "## Begin by deciding how many neighbors (data points from your dataset) you want to consider when making predictions. This value is your K.\n",
    "## Very low values of K (e.g., 1 or 2) can lead to overfitting because predictions become too sensitive to individual data points.\n",
    "## Very high values of K (e.g., much larger than the square root of the number of data points) may result in underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ae7c7b-005e-49c6-b24f-80f57ee303ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "## The KNN classifier is used for classification tasks.\n",
    "## The KNN classifier is used for regression tasks.\n",
    "## It predicts the class label of a data point based on the majority class among its k nearest neighbors.\n",
    "## It predicts a continuous value (numeric output) based on the mean of the nearest neighbor labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123c1e53-5258-4e3f-99c3-7952744c95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4. How do you measure the performance of KNN?\n",
    "\n",
    "## KNN relies on a distance metric to find the nearest neighbors. Commonly used distance metrics include:\n",
    "## Euclidean distance: Measures the straight-line distance between two points in Euclidean space.\n",
    "## Manhattan distance: Also known as taxicab distance, it considers the sum of absolute differences along each dimension.\n",
    "## Minkowski distance: A generalized metric that includes both Euclidean and Manhattan distances (controlled by a parameter p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c104be74-b8a0-4a2b-9d07-01843c033e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "## he curse of dimensionality refers to a phenomenon that affects machine learning algorithms, particularly those relying on distance-based measures \n",
    "## As the number of dimensions (features) in a dataset increases, the volume of the space also grows exponentially.\n",
    "## onsequently, the density of data points becomes sparse in high-dimensional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c8ceab-536c-489f-9af2-5105a46b074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q6. How do you handle missing values in KNN?\n",
    "\n",
    "## dentify the rows (data points) with missing values.\n",
    "## For each missing value, find the k nearest neighbors (based on a distance metric) that have valid values for that feature.\n",
    "## Predict the missing value by averaging or using the majority value from these neighbors.\n",
    "## This process is often referred to as nearest neighbor imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620d0bb6-67d1-44e1-a112-de7ffeb52709",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "## which type of problem?\n",
    "\n",
    "## KNN Classifier:\n",
    "## Objective: The KNN classifier predicts the class label of a data point based on the majority class among its k nearest neighbors.\n",
    "## Output: Discrete values (class labels).\n",
    "## dvantages:\n",
    "## Simple to implement.\n",
    "## Handles both numerical and categorical features.\n",
    "\n",
    "## KNN regressor\n",
    "## Objective: The KNN regressor predicts a continuous value (numeric output) based on the mean of the nearest neighbor labels.\n",
    "## Output: Continuous values (numeric predictions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425c91e-d401-4aab-9512-59d882a350ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "## Euclidean Distance:\n",
    "## Definition: Euclidean distance is the measure of the true straight-line distance between two points in Euclidean space (like the familiar Cartesian plane)\n",
    "## Formula: Given two points ((x_1, y_1)) and ((x_2, y_2)), the Euclidean distance (d_{\\text{Euclidean}}) is calculated as: [ d_{\\text{Euclidean}} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} ]\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
